# Global setting: Toggle to TRUE for feedback version, FALSE for exam version
show_interpretation <- TRUE
#load libraries
library(stargazer)
library(psych)
library(ggplot2)
library(car)
# Load dataset
df <- read.csv(file="Data_Sub_AK91.csv",header=T,sep = ",")
head(df)
#Creation of dummy vars for the regions and QOBs
REGION2 = ifelse(df$REGION == 2, 1, 0)
REGION3 = ifelse(df$REGION == 3, 1, 0)
REGION4 = ifelse(df$REGION == 4, 1, 0)
REGION5 = ifelse(df$REGION == 5, 1, 0)
REGION6 = ifelse(df$REGION == 6, 1, 0)
REGION7 = ifelse(df$REGION == 7, 1, 0)
REGION8 = ifelse(df$REGION == 8, 1, 0)
REGION9 = ifelse(df$REGION == 9, 1, 0)
QOB2 = ifelse(df$QOB == 2, 1, 0)
QOB3 = ifelse(df$QOB == 3, 1, 0)
QOB4 = ifelse(df$QOB == 4, 1, 0)
summary(df)
describe(df)
cov(df)
cor(df)
ggplot(df, aes(x = df$EDUC, y = df$WAGE)) +
geom_point(color = "blue") +
labs(title = "Relationship Between Education and Wage",
x = "Years of Education",
y = "Weekly Wage (in $)") + ylim(0, 600) +
theme_minimal()
#linear model
linear_model1=lm(df$WAGE~ df$EDUC + df$AGE + df$RACE + df$SMSA + df$MARRIED + REGION2 + REGION3 + REGION4 + REGION5 + REGION6 + REGION7 + REGION8 + REGION9 + QOB2 + QOB3 + QOB4)
stargazer(linear_model1,type="text",style="all")
if (show_interpretation) {
cat("\nRegions 2, 3, and 9 have significantly higher wages compared to the reference region 1.")
}
# Joint significance test: Test whether AGE, RACE, MARRIED, and SMSA jointly contribute to explaining WAGE.
linearHypothesis(linear_model1, c("df$AGE = 0", "df$RACE = 0", "df$MARRIED = 0", "df$SMSA = 0"))
#Assess whether regional differences are statistically significant.
linearHypothesis(linear_model1, c("REGION2 = 0","REGION3 = 0", "REGION4 = 0", "REGION5 = 0", "REGION6 = 0", "REGION7 = 0", "REGION8 = 0", "REGION9 = 0" ))
if (show_interpretation) {
cat("\nSince the p-value is extremely small (<0.001), we reject the null hypothesis. This means that at least one of the region coefficients is significantly different from zero, implying that region does have a statistically significant effect on wages.")
}
if (show_interpretation) {
cat("Interpretation (Visible Only in Feedback Mode)\n\n")  # Extra newline for spacing
cat("If income increases by 1 dollar, consumption is expected to rise by 0.51 dollars.\n")
}
# Global setting: Toggle to TRUE for feedback version, FALSE for exam version
show_interpretation <- TRUE
#load libraries
library(stargazer)
library(psych)
library(ggplot2)
library(car)
# Load dataset
df <- read.csv(file="Data_Sub_AK91.csv",header=T,sep = ",")
head(df)
#Creation of dummy vars for the regions and QOBs
REGION2 = ifelse(df$REGION == 2, 1, 0)
REGION3 = ifelse(df$REGION == 3, 1, 0)
REGION4 = ifelse(df$REGION == 4, 1, 0)
REGION5 = ifelse(df$REGION == 5, 1, 0)
REGION6 = ifelse(df$REGION == 6, 1, 0)
REGION7 = ifelse(df$REGION == 7, 1, 0)
REGION8 = ifelse(df$REGION == 8, 1, 0)
REGION9 = ifelse(df$REGION == 9, 1, 0)
QOB2 = ifelse(df$QOB == 2, 1, 0)
QOB3 = ifelse(df$QOB == 3, 1, 0)
QOB4 = ifelse(df$QOB == 4, 1, 0)
summary(df)
describe(df)
cov(df)
cor(df)
ggplot(df, aes(x = df$EDUC, y = df$WAGE)) +
geom_point(color = "blue") +
labs(title = "Relationship Between Education and Wage",
x = "Years of Education",
y = "Weekly Wage (in $)") + ylim(0, 1200) +
theme_minimal()
#linear model
linear_model1=lm(df$WAGE~ df$EDUC + df$AGE + df$RACE + df$SMSA + df$MARRIED + REGION2 + REGION3 + REGION4 + REGION5 + REGION6 + REGION7 + REGION8 + REGION9 + QOB2 + QOB3 + QOB4)
stargazer(linear_model1,type="text",style="all")
if (show_interpretation) {
cat("\nRegions 2, 3, and 9 have significantly higher wages compared to the reference region 1.")
}
# Joint significance test: Test whether AGE, RACE, MARRIED, and SMSA jointly contribute to explaining WAGE.
linearHypothesis(linear_model1, c("df$AGE = 0", "df$RACE = 0", "df$MARRIED = 0", "df$SMSA = 0"))
#Assess whether regional differences are statistically significant.
linearHypothesis(linear_model1, c("REGION2 = 0","REGION3 = 0", "REGION4 = 0", "REGION5 = 0", "REGION6 = 0", "REGION7 = 0", "REGION8 = 0", "REGION9 = 0" ))
if (show_interpretation) {
cat("\nSince the p-value is extremely small (<0.001), we reject the null hypothesis. This means that at least one of the region coefficients is significantly different from zero, implying that region does have a statistically significant effect on wages.")
}
if (show_interpretation) {
cat("Interpretation (Visible Only in Feedback Mode)\n\n")  # Extra newline for spacing
cat("If income increases by 1 dollar, consumption is expected to rise by 0.51 dollars.\n")
}
# Global setting: Toggle to TRUE for feedback version, FALSE for exam version
show_interpretation <- TRUE
#load libraries
library(stargazer)
library(psych)
library(ggplot2)
library(car)
# Load dataset
df <- read.csv(file="Data_Sub_AK91.csv",header=T,sep = ",")
if (show_interpretation) {
cat("
H0:  β2 = 0  Education has no effect on wages.
H1:  β2 > 0  Education has a positive effect on wages.
One-sided hypotheses are appropriate in this case because education is expected to increase earnings (according to economic theories). In addition, there’s often little reason to test whether more education reduces wages because that result is counterintuitive."
)
}
head(df)
#Creation of dummy vars for the regions and QOBs
REGION2 = ifelse(df$REGION == 2, 1, 0)
REGION3 = ifelse(df$REGION == 3, 1, 0)
REGION4 = ifelse(df$REGION == 4, 1, 0)
REGION5 = ifelse(df$REGION == 5, 1, 0)
REGION6 = ifelse(df$REGION == 6, 1, 0)
REGION7 = ifelse(df$REGION == 7, 1, 0)
REGION8 = ifelse(df$REGION == 8, 1, 0)
REGION9 = ifelse(df$REGION == 9, 1, 0)
QOB2 = ifelse(df$QOB == 2, 1, 0)
QOB3 = ifelse(df$QOB == 3, 1, 0)
QOB4 = ifelse(df$QOB == 4, 1, 0)
summary(df)
describe(df)
cov(df)
cor(df)
ggplot(df, aes(x = df$EDUC, y = df$WAGE)) +
geom_point(color = "blue") +
labs(title = "Relationship Between Education and Wage",
x = "Years of Education",
y = "Weekly Wage (in $)") + ylim(0, 1200) +
theme_minimal()
#linear model
linear_model1=lm(df$WAGE~ df$EDUC + df$AGE + df$RACE + df$SMSA + df$MARRIED + REGION2 + REGION3 + REGION4 + REGION5 + REGION6 + REGION7 + REGION8 + REGION9 + QOB2 + QOB3 + QOB4)
stargazer(linear_model1,type="text",style="all")
if (show_interpretation) {
cat("\n EDUC (26.729, p < 0.001)
A one-year increase in education leads to a $26.73 increase in wages.
This is highly significant (p = 0.000).
AGE (2.226, p = 0.020)
A one-year increase in age increases wages by $2.23.
Significant at the 5% level (p = 0.020).
RACE (-77.478, p < 0.001)
Suggests a wage penalty of $77.48 for certain racial groups (assuming a binary variable where non-white = 1).
Highly significant (p = 0.000).
SMSA (-63.654, p < 0.001)
Living in an SMSA (Standard Metropolitan Statistical Area) is associated with a $63.65 lower wage.
Significant at p = 0.000.
MARRIED (77.927, p < 0.001)
Being married increases wages by $77.93.
Highly significant (p = 0.000).
Regional Effects on Wages
Significant Regions:
REGION2 ($\beta$ = 41.204, p = 0.003)
REGION3 ($\beta$ = 49.071, p = 0.0003)
REGION9 ($\beta$ = 63.543, p = 0.00001)
These regions have higher wages compared to the reference region.
Non-Significant Regions:
REGION4, REGION5, REGION6, REGION7, REGION8 (p > 0.05)
These regions do not significantly differ from the reference region in terms of wages.
Regions 2, 3, and 9 have significantly higher wages compared to the reference region 1.")
}
# Joint significance test: Test whether AGE, RACE, MARRIED, and SMSA jointly contribute to explaining WAGE.
linearHypothesis(linear_model1, c("df$AGE = 0", "df$RACE = 0", "df$MARRIED = 0", "df$SMSA = 0"))
#Assess whether regional differences are statistically significant.
linearHypothesis(linear_model1, c("REGION2 = 0","REGION3 = 0", "REGION4 = 0", "REGION5 = 0", "REGION6 = 0", "REGION7 = 0", "REGION8 = 0", "REGION9 = 0" ))
if (show_interpretation) {
cat("\nSince the p-value is extremely small (<0.001), we reject the null hypothesis. This means that at least one of the region coefficients is significantly different from zero, implying that region does have a statistically significant effect on wages.")
}
if (show_interpretation) {
cat("Interpretation (Visible Only in Feedback Mode)\n\n")  # Extra newline for spacing
cat("If income increases by 1 dollar, consumption is expected to rise by 0.51 dollars.\n")
}
print(var(df&EDUC))
print(var(df$EDUC))
print(var(df$EDUC))
print(var(df$AGE))
print(var(df$EDUC))
print(var(df$MARRIED))
# Global setting: Toggle to TRUE for feedback version, FALSE for exam version
show_interpretation <- TRUE
#load libraries
library(stargazer)
library(psych)
library(ggplot2)
library(car)
# Load dataset
df <- read.csv(file="Data_Sub_AK91.csv",header=T,sep = ",")
if (show_interpretation) {
cat("
H0:  β2 = 0  Education has no effect on wages.
H1:  β2 > 0  Education has a positive effect on wages.
One-sided hypotheses are appropriate in this case because education is expected to increase earnings (according to economic theories). In addition, there’s often little reason to test whether more education reduces wages because that result is counterintuitive."
)
}
head(df)
#Creation of dummy vars for the regions and QOBs
REGION2 = ifelse(df$REGION == 2, 1, 0)
REGION3 = ifelse(df$REGION == 3, 1, 0)
REGION4 = ifelse(df$REGION == 4, 1, 0)
REGION5 = ifelse(df$REGION == 5, 1, 0)
REGION6 = ifelse(df$REGION == 6, 1, 0)
REGION7 = ifelse(df$REGION == 7, 1, 0)
REGION8 = ifelse(df$REGION == 8, 1, 0)
REGION9 = ifelse(df$REGION == 9, 1, 0)
QOB2 = ifelse(df$QOB == 2, 1, 0)
QOB3 = ifelse(df$QOB == 3, 1, 0)
QOB4 = ifelse(df$QOB == 4, 1, 0)
summary(df)
describe(df)
cov(df)
cor(df)
ggplot(df, aes(x = df$EDUC, y = df$WAGE)) +
geom_point(color = "blue") +
labs(title = "Relationship Between Education and Wage",
x = "Years of Education",
y = "Weekly Wage (in $)") + ylim(0, 1200) +
theme_minimal()
#linear model
linear_model1=lm(df$WAGE~ df$EDUC + df$AGE + df$RACE + df$SMSA + df$MARRIED + REGION2 + REGION3 + REGION4 + REGION5 + REGION6 + REGION7 + REGION8 + REGION9 + QOB2 + QOB3 + QOB4)
stargazer(linear_model1,type="text",style="all")
if (show_interpretation) {
cat("\n EDUC (26.729, p < 0.001)
A one-year increase in education leads to a $26.73 increase in wages.
This is highly significant (p = 0.000).
AGE (2.226, p = 0.020)
A one-year increase in age increases wages by $2.23.
Significant at the 5% level (p = 0.020).
RACE (-77.478, p < 0.001)
Suggests a wage penalty of $77.48 for certain racial groups (assuming a binary variable where non-white = 1).
Highly significant (p = 0.000).
SMSA (-63.654, p < 0.001)
Living in an SMSA (Standard Metropolitan Statistical Area) is associated with a $63.65 lower wage.
Significant at p = 0.000.
MARRIED (77.927, p < 0.001)
Being married increases wages by $77.93.
Highly significant (p = 0.000).
Regional Effects on Wages
Significant Regions:
REGION2 ($\beta$ = 41.204, p = 0.003)
REGION3 ($\beta$ = 49.071, p = 0.0003)
REGION9 ($\beta$ = 63.543, p = 0.00001)
These regions have higher wages compared to the reference region.
Non-Significant Regions:
REGION4, REGION5, REGION6, REGION7, REGION8 (p > 0.05)
These regions do not significantly differ from the reference region in terms of wages.")
}
# Joint significance test: Test whether AGE, RACE, MARRIED, and SMSA jointly contribute to explaining WAGE.
linearHypothesis(linear_model1, c("df$AGE = 0", "df$RACE = 0", "df$MARRIED = 0", "df$SMSA = 0"))
#Assess whether regional differences are statistically significant.
linearHypothesis(linear_model1, c("REGION2 = 0","REGION3 = 0", "REGION4 = 0", "REGION5 = 0", "REGION6 = 0", "REGION7 = 0", "REGION8 = 0", "REGION9 = 0" ))
if (show_interpretation) {
cat("\nSince the p-value is extremely small (<0.001), we reject the null hypothesis. This means that at least one of the region coefficients is significantly different from zero, implying that region does have a statistically significant effect on wages.")
}
if (show_interpretation) {
cat("Interpretation (Visible Only in Feedback Mode)\n\n")  # Extra newline for spacing
cat("If income increases by 1 dollar, consumption is expected to rise by 0.51 dollars.\n")
}
print(var(df$EDUC))
print(var(df$MARRIED))
plot(linear_model1$fitted.values, resid(linear_model1),
main = "Residuals vs. Fitted Values",
xlab = "Fitted Values",
ylab = "Residuals",
pch = 16, col = "blue")
abline(h = 0, lty = 2, col = "red")  # Add a reference line at zero
plot(linear_model1$fitted.values, resid(linear_model1),
main = "Residuals vs. Fitted Values",
xlab = "Fitted Values",
ylab = "Residuals",
pch = 16, col = "blue")
abline(h = 0, lty = 2, col = "red")  # Add a reference line at zero
qqnorm(resid(linearmodel1), main = "Q-Q Plot of Residuals", pch = 16, col = "blue")
qqnorm(resid(linear_model1), main = "Q-Q Plot of Residuals", pch = 16, col = "blue")
qqline(resid(linear_model1), col = "red", lwd = 2)  # Add a reference line
# Global setting: Toggle to TRUE for feedback version, FALSE for exam version
show_interpretation <-TRUE
#load libraries
library(stargazer)
library(psych)
library(ggplot2)
library(car)
# Load dataset
df <- read.csv(file="Data_Sub_AK91.csv",header=T,sep = ",")
if (isTRUE(show_interpretation)) {
cat("### Hypothesis Testing\n\n")  # Adds a Markdown header for clarity
cat("**H₀:** β₂ = 0 → Education has no effect on wages.\n\n")
cat("**H₁:** β₂ > 0 → Education has a positive effect on wages.\n\n")
cat("One-sided hypotheses are appropriate in this case because education is expected to increase earnings (according to economic theories).
In addition, there’s often little reason to test whether more education reduces wages because that result is counterintuitive.")
}
head(df)
#Creation of dummy vars for the regions and QOBs
REGION2 = ifelse(df$REGION == 2, 1, 0)
REGION3 = ifelse(df$REGION == 3, 1, 0)
REGION4 = ifelse(df$REGION == 4, 1, 0)
REGION5 = ifelse(df$REGION == 5, 1, 0)
REGION6 = ifelse(df$REGION == 6, 1, 0)
REGION7 = ifelse(df$REGION == 7, 1, 0)
REGION8 = ifelse(df$REGION == 8, 1, 0)
REGION9 = ifelse(df$REGION == 9, 1, 0)
QOB2 = ifelse(df$QOB == 2, 1, 0)
QOB3 = ifelse(df$QOB == 3, 1, 0)
QOB4 = ifelse(df$QOB == 4, 1, 0)
summary(df)
describe(df)
cov(df)
cor(df)
ggplot(df, aes(x = df$EDUC, y = df$WAGE)) +
geom_point(color = "blue") +
labs(title = "Relationship Between Education and Wage",
x = "Years of Education",
y = "Weekly Wage (in $)") + ylim(0, 1200) +
theme_minimal()
#linear model
linear_model1=lm(df$WAGE~ df$EDUC + df$AGE + df$RACE + df$SMSA + df$MARRIED + REGION2 + REGION3 + REGION4 + REGION5 + REGION6 + REGION7 + REGION8 + REGION9 + QOB2 + QOB3 + QOB4)
stargazer(linear_model1,type="text",style="all")
if (show_interpretation) {
cat("### Betekenis coef \n\n")
cat("\n EDUC (26.729, p < 0.001)
A one-year increase in education leads to a $26.73 increase in wages.
This is highly significant (p = 0.000).
AGE (2.226, p = 0.020)
A one-year increase in age increases wages by $2.23.
Significant at the 5% level (p = 0.020).
RACE (-77.478, p < 0.001)
Suggests a wage penalty of $77.48 for certain racial groups (assuming a binary variable where non-white = 1).
Highly significant (p = 0.000).
SMSA (-63.654, p < 0.001)
Living in an SMSA (Standard Metropolitan Statistical Area) is associated with a $63.65 lower wage.
Significant at p = 0.000.
MARRIED (77.927, p < 0.001)
Being married increases wages by $77.93.
Highly significant (p = 0.000).
Regional Effects on Wages
Significant Regions:
REGION2 (β = 41.204, p = 0.003)
REGION3 (β = 49.071, p = 0.0003)
REGION9 (β = 63.543, p = 0.00001)
These regions have higher wages compared to the reference region.
Non-Significant Regions:
REGION4, REGION5, REGION6, REGION7, REGION8 (p > 0.05)
These regions do not significantly differ from the reference region in terms of wages.")
}
# Joint significance test: Test whether AGE, RACE, MARRIED, and SMSA jointly contribute to explaining WAGE.
linearHypothesis(linear_model1, c("df$AGE = 0", "df$RACE = 0", "df$MARRIED = 0", "df$SMSA = 0"))
#Assess whether regional differences are statistically significant.
linearHypothesis(linear_model1, c("REGION2 = 0","REGION3 = 0", "REGION4 = 0", "REGION5 = 0", "REGION6 = 0", "REGION7 = 0", "REGION8 = 0", "REGION9 = 0" ))
if (show_interpretation) {
cat("\nSince the p-value is extremely small (<0.001), we reject the null hypothesis. This means that at least one of the region coefficients is significantly different from zero, implying that region does have a statistically significant effect on wages.")
}
plot(linear_model1$fitted.values, resid(linear_model1),
main = "Residuals vs. Fitted Values",
xlab = "Fitted Values",
ylab = "Residuals",
pch = 16, col = "blue")
abline(h = 0, lty = 2, col = "red")  # Add a reference line at zero
qqnorm(resid(linear_model1), main = "Q-Q Plot of Residuals", pch = 16, col = "blue")
qqline(resid(linear_model1), col = "red", lwd = 2)  # Add a reference line
if (show_interpretation) {
cat("Interpretation (Visible Only in Feedback Mode)\n\n")  # Extra newline for spacing
cat("If income increases by 1 dollar, consumption is expected to rise by 0.51 dollars.\n")
}
print(var(df$EDUC))
print(var(df$MARRIED))
<<<<<<< Updated upstream
# Updated upstream
# Residuen opslaan
residuals <- residuals(linear_model1)
# Histogram van de residuen
ggplot(data.frame(residuals), aes(x = residuals)) +
geom_histogram(binwidth = 5, color = "black", fill = "blue", alpha = 0.7) +
labs(title = "Histogram van de Residuen", x = "Residuals", y = "Frequentie") +
theme_minimal()
# Q-Q plot
qqnorm(residuals)
qqline(residuals, col = "red", lwd = 2)
# Jarque-Bera test uitvoeren
jarque.bera.test(residuals)
install.packages("tseries")
# Updated upstream
# Residuen opslaan
residuals <- residuals(linear_model1)
# Histogram van de residuen
ggplot(data.frame(residuals), aes(x = residuals)) +
geom_histogram(binwidth = 5, color = "black", fill = "blue", alpha = 0.7) +
labs(title = "Histogram van de Residuen", x = "Residuals", y = "Frequentie") +
theme_minimal()
# Q-Q plot
qqnorm(residuals)
qqline(residuals, col = "red", lwd = 2)
# Jarque-Bera test uitvoeren
jarque.bera.test(residuals)
# Updated upstream
# Residuen opslaan
residuals <- residuals(linear_model1)
# Histogram van de residuen
ggplot(data.frame(residuals), aes(x = residuals)) +
geom_histogram(binwidth = 5, color = "black", fill = "blue", alpha = 0.7) +
labs(title = "Histogram van de Residuen", x = "Residuals", y = "Frequentie") +
theme_minimal()
# Q-Q plot
qqnorm(residuals)
qqline(residuals, col = "red", lwd = 2)
# Jarque-Bera test uitvoeren
jarque.bera.test(residuals)
